{
 "metadata": {
  "name": "",
  "signature": "sha256:5c09f453a1d502202d52035846a639bbda0e91895a4bfda3ee5e08e7c0316dcf"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Brownback's Tax Cuts\n",
      "##A Relatively Lazy Investigation\n",
      "\n",
      "I don't think Sam Brownback believes he's an evil guy, so I'll give him the benefit of the doubt and assume that somewhere in some time series that he has access to he had good reason to believe in his tax cuts. More specifically, that there's a case in publicly available data in which cutting top marginal income tax rates while doing nothing to offset the cut creates \"tens of thousands of new jobs\" and a huge influx of migrants to the low top tax-rate utopia. I don't know that I'll find anything, but I'll do my best.\n",
      "\n",
      "Data come from the NBER's [TAXSIM](http://users.nber.org/~taxsim/state-rates/) series on top marginal tax rates and [IPUMS](https://usa.ipums.org/usa/)'s migration, employment, and income data. It will be obvious which variables are in use once there's some data work to show."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "from statsmodels.api import Logit, OLS\n",
      "\n",
      "from urllib2 import urlopen\n",
      "\n",
      "#read in top marginal tax rates data\n",
      "url = 'http://users.nber.org/~taxsim/state-rates/maxrate.dat'\n",
      "f = urlopen('http://users.nber.org/~taxsim/state-rates/maxrate.dat')\n",
      "headers_f = ['Year','State ID','Federal Rate, Wages','State Rate, Wages',\n",
      "             'Total Rate, Wages','Federal Rate, Long Gains','State Rate, Long Gains',\n",
      "             'Total Rate, Long Gains','Federal Rate, Mortgage Deduction',\n",
      "             'State Rate, Mortgage Deduction','Total Rate, Mortgage Deduction',\n",
      "             'State Name']\n",
      "\n",
      "types = {'Year': np.int64,\n",
      "         'State ID': str,\n",
      "         'Federal Rate, Wages': np.float32,\n",
      "         'State Rate, Wages': np.float32,\n",
      "         'Total Rate, Wages': np.float32,\n",
      "         'Federal Rate, Long Gains': np.float32,\n",
      "         'State Rate, Long Gains': np.float32,\n",
      "         'Total Rate, Long Gains': np.float32,\n",
      "         'Federal Rate, Mortgage Deduction': np.float32,\n",
      "         'State Rate, Mortgage Deduction': np.float32,\n",
      "         'Total Rate, Mortgage Deduction': np.float32,\n",
      "         'State Name': str}\n",
      "\n",
      "tax_rates = pd.read_fwf(f, header = None,\n",
      "                        names = headers_f,\n",
      "                        index_col = [11,0])\n",
      "f.close()\n",
      "\n",
      "tax_rates = tax_rates[['State Rate, Wages','State Rate, Long Gains']]\n",
      "for col in tax_rates.columns:\n",
      "    tax_rates[col] = pd.Series(tax_rates[col], dtype = types[col])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tax_rates.loc['Connecticut']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>State Rate, Wages</th>\n",
        "      <th>State Rate, Long Gains</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Year</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>1977</th>\n",
        "      <td> 0.0</td>\n",
        "      <td> 3.50</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1978</th>\n",
        "      <td> 0.0</td>\n",
        "      <td> 2.80</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1979</th>\n",
        "      <td> 0.0</td>\n",
        "      <td> 2.80</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1980</th>\n",
        "      <td> 0.0</td>\n",
        "      <td> 2.80</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1981</th>\n",
        "      <td> 0.0</td>\n",
        "      <td> 2.80</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1982</th>\n",
        "      <td> 0.0</td>\n",
        "      <td> 2.80</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1983</th>\n",
        "      <td> 0.0</td>\n",
        "      <td> 2.80</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1984</th>\n",
        "      <td> 0.0</td>\n",
        "      <td> 2.80</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1985</th>\n",
        "      <td> 0.0</td>\n",
        "      <td> 2.80</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1986</th>\n",
        "      <td> 0.0</td>\n",
        "      <td> 2.80</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1987</th>\n",
        "      <td> 0.0</td>\n",
        "      <td> 2.80</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1988</th>\n",
        "      <td> 0.0</td>\n",
        "      <td> 2.80</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1989</th>\n",
        "      <td> 0.0</td>\n",
        "      <td> 7.00</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1990</th>\n",
        "      <td> 0.0</td>\n",
        "      <td> 7.00</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1991</th>\n",
        "      <td> 1.5</td>\n",
        "      <td> 6.25</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1992</th>\n",
        "      <td> 4.5</td>\n",
        "      <td> 4.50</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1993</th>\n",
        "      <td> 4.5</td>\n",
        "      <td> 4.50</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1994</th>\n",
        "      <td> 4.5</td>\n",
        "      <td> 4.50</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1995</th>\n",
        "      <td> 4.5</td>\n",
        "      <td> 4.50</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1996</th>\n",
        "      <td> 4.5</td>\n",
        "      <td> 4.50</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1997</th>\n",
        "      <td> 4.5</td>\n",
        "      <td> 4.50</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1998</th>\n",
        "      <td> 4.5</td>\n",
        "      <td> 4.50</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1999</th>\n",
        "      <td> 4.5</td>\n",
        "      <td> 4.50</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2000</th>\n",
        "      <td> 4.5</td>\n",
        "      <td> 4.50</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2001</th>\n",
        "      <td> 4.5</td>\n",
        "      <td> 4.50</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2002</th>\n",
        "      <td> 4.5</td>\n",
        "      <td> 4.50</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2003</th>\n",
        "      <td> 5.0</td>\n",
        "      <td> 5.00</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2004</th>\n",
        "      <td> 5.0</td>\n",
        "      <td> 5.00</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2005</th>\n",
        "      <td> 5.0</td>\n",
        "      <td> 5.00</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2006</th>\n",
        "      <td> 5.0</td>\n",
        "      <td> 5.00</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2007</th>\n",
        "      <td> 5.0</td>\n",
        "      <td> 5.00</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2008</th>\n",
        "      <td> 5.0</td>\n",
        "      <td> 5.00</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2009</th>\n",
        "      <td> 6.5</td>\n",
        "      <td> 6.50</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2010</th>\n",
        "      <td> 6.5</td>\n",
        "      <td> 6.50</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2011</th>\n",
        "      <td> 6.7</td>\n",
        "      <td> 6.70</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2012</th>\n",
        "      <td> 6.7</td>\n",
        "      <td> 6.70</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 54,
       "text": [
        "      State Rate, Wages  State Rate, Long Gains\n",
        "Year                                           \n",
        "1977                0.0                    3.50\n",
        "1978                0.0                    2.80\n",
        "1979                0.0                    2.80\n",
        "1980                0.0                    2.80\n",
        "1981                0.0                    2.80\n",
        "1982                0.0                    2.80\n",
        "1983                0.0                    2.80\n",
        "1984                0.0                    2.80\n",
        "1985                0.0                    2.80\n",
        "1986                0.0                    2.80\n",
        "1987                0.0                    2.80\n",
        "1988                0.0                    2.80\n",
        "1989                0.0                    7.00\n",
        "1990                0.0                    7.00\n",
        "1991                1.5                    6.25\n",
        "1992                4.5                    4.50\n",
        "1993                4.5                    4.50\n",
        "1994                4.5                    4.50\n",
        "1995                4.5                    4.50\n",
        "1996                4.5                    4.50\n",
        "1997                4.5                    4.50\n",
        "1998                4.5                    4.50\n",
        "1999                4.5                    4.50\n",
        "2000                4.5                    4.50\n",
        "2001                4.5                    4.50\n",
        "2002                4.5                    4.50\n",
        "2003                5.0                    5.00\n",
        "2004                5.0                    5.00\n",
        "2005                5.0                    5.00\n",
        "2006                5.0                    5.00\n",
        "2007                5.0                    5.00\n",
        "2008                5.0                    5.00\n",
        "2009                6.5                    6.50\n",
        "2010                6.5                    6.50\n",
        "2011                6.7                    6.70\n",
        "2012                6.7                    6.70"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we have all of the top tax rates for states from 2000 on, which will allow us to identify when each state decreased its top tax rate. This is not quite the same as Brownback's program and does nothing to account for the [varieties of tax credits](http://www.irs.gov/Credits-&-Deductions) available for different reasons at the federal or state level. Next step is identifying the state-year combinations we're interested in."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "state_years = {}\n",
      "\n",
      "def find_years(state, direction = 'decrease'):\n",
      "    \n",
      "    years = []\n",
      "    filtered = tax_rates.loc[s]\n",
      "    for year in np.linspace(2001,2012,12,dtype = np.int64):\n",
      "        if direction == 'decrease':\n",
      "            if filtered.loc[year,'State Rate, Wages'] < filtered.loc[year-1,'State Rate, Wages']:\n",
      "                years += [year]\n",
      "        elif direction == 'increase':\n",
      "            if filtered.loc[year,'State Rate, Wages'] > filtered.loc[year-1,'State Rate, Wages']:\n",
      "                years += [year]\n",
      "        else:\n",
      "            print 'Direction must be \\'increase\\' or \\'decrease\\''\n",
      "    state_years[state] = years\n",
      "    \n",
      "for s in pd.unique(tax_rates.index.get_level_values('State Name')):\n",
      "    find_years(s, direction = 'decrease')\n",
      "\n",
      "#years of decrease\n",
      "state_years"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 59,
       "text": [
        "{'Alabama': [],\n",
        " 'Alaska': [],\n",
        " 'Arizona': [2006, 2007, 2008, 2010],\n",
        " 'Arkansas': [2005, 2009, 2010],\n",
        " 'California': [2011],\n",
        " 'Colorado': [2006, 2008, 2010],\n",
        " 'Connecticut': [],\n",
        " 'Delaware': [2006, 2008, 2010, 2012],\n",
        " 'Florida': [],\n",
        " 'Georgia': [2006, 2008, 2010],\n",
        " 'Hawaii': [2001, 2002, 2006, 2008, 2010],\n",
        " 'Idaho': [2001, 2006, 2008, 2010, 2012],\n",
        " 'Illinois': [],\n",
        " 'Indiana': [],\n",
        " 'Iowa': [2008],\n",
        " 'Kansas': [2006, 2008],\n",
        " 'Kentucky': [2006, 2008, 2010],\n",
        " 'Louisiana': [2007, 2008, 2009, 2010],\n",
        " 'Maine': [2006, 2008, 2010],\n",
        " 'Maryland': [2001, 2002, 2006, 2010, 2012],\n",
        " 'Massachusetts': [2001, 2002, 2012],\n",
        " 'Michigan': [2002, 2003, 2004, 2005, 2012],\n",
        " 'Minnesota': [2006, 2008, 2010, 2012],\n",
        " 'Mississippi': [2006, 2008, 2010],\n",
        " 'Missouri': [2006, 2008, 2010],\n",
        " 'Montana': [2005, 2006, 2008, 2010],\n",
        " 'Nebraska': [2008],\n",
        " 'Nevada': [],\n",
        " 'New Hampshire': [],\n",
        " 'New Jersey': [2010],\n",
        " 'New Mexico': [2003, 2004, 2005, 2006, 2008, 2010],\n",
        " 'New York': [2006, 2008, 2010, 2012],\n",
        " 'North Carolina': [2006, 2007, 2008, 2010, 2011],\n",
        " 'North Dakota': [2006, 2008, 2009, 2010, 2011],\n",
        " 'Ohio': [2005, 2006, 2007, 2008, 2011],\n",
        " 'Oklahoma': [2006, 2007, 2008, 2010],\n",
        " 'Oregon': [2006, 2008, 2010, 2012],\n",
        " 'Pennsylvania': [],\n",
        " 'Rhode Island': [2001, 2002, 2006, 2007, 2008, 2009, 2010, 2011],\n",
        " 'South Carolina': [2006, 2008, 2010],\n",
        " 'South Dakota': [],\n",
        " 'Tennessee': [],\n",
        " 'Texas': [],\n",
        " 'Utah': [2006, 2007, 2008],\n",
        " 'Vermont': [2001, 2006, 2008, 2009, 2010],\n",
        " 'Virginia': [2006, 2008, 2010],\n",
        " 'Washington': [],\n",
        " 'Washington DC': [2001, 2005, 2006, 2007, 2008, 2010],\n",
        " 'West Virginia': [],\n",
        " 'Wisconsin': [],\n",
        " 'Wyoming': []}"
       ]
      }
     ],
     "prompt_number": 59
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Handling the migration data is a little more difficult. Dataset containing individual-level migration and employment status data for 2000-2012 is a 1.7gb file, which would probably fit in memory, but that's no way to learn new things, so instead it's in a PgSQL database."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import psycopg2\n",
      "\n",
      "try: \n",
      "    con = psycopg2.connect(database='james', user='james') \n",
      "    cur = con.cursor()\n",
      "    \n",
      "except psycopg2.DatabaseError, e:\n",
      "    print 'Error %s' % e    \n",
      "    sys.exit(1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 56
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Goal at this point is:\n",
      "\n",
      "1. for each state with a tax decrease and at least four years between that decrease and their next tax decrease, calculate net migration for each other state in each of those next four years (including the tax change year).\n",
      "2. generate  bunch of plots showing what this looks like for each state\n",
      "3. map these things (maybe)\n",
      "4. do similar tests to income and employment status following tax rates (breaking out migrants vs. people who lived in KS to begin with)\n",
      "\n",
      "###Calculate Net Migration for Each State with at least 3 Years Between Tax Changes\n",
      "\n",
      "The lists in the state_years items are, fortunately, ordered, which gives us some good options."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "state_years = {s:np.array(state_years[s]) for s in state_years.keys()}\n",
      "state_years_trim = {}\n",
      "\n",
      "def trim_to_n_yr_gaps(state, n = 4):\n",
      "    check = state_years[state]\n",
      "    try:\n",
      "        if check[-1] <= 2013 - n:\n",
      "            return np.array(list(check[np.diff(check) >= n]) + [check[-1]], dtype = np.int32)\n",
      "        else:\n",
      "            return check[np.diff(check) >= n]\n",
      "    except(IndexError):\n",
      "        print '{0} has no top income tax rate decreases in 2000 to 2012.'.format(state)\n",
      "        return np.array([])\n",
      "\n",
      "for s in state_years.keys():\n",
      "    state_years_trim[s] = trim_to_n_yr_gaps(s, n = 4)\n",
      "    \n",
      "state_years_trim = {k:v for k, v in state_years_trim.items() if v.any()}\n",
      "state_years_trim"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Wyoming has no top income tax rate decreases in 2000 to 2012.\n",
        "Illinois has no top income tax rate decreases in 2000 to 2012.\n",
        "Indiana has no top income tax rate decreases in 2000 to 2012.\n",
        "Connecticut has no top income tax rate decreases in 2000 to 2012.\n",
        "West Virginia has no top income tax rate decreases in 2000 to 2012.\n",
        "New Hampshire has no top income tax rate decreases in 2000 to 2012.\n",
        "Pennsylvania has no top income tax rate decreases in 2000 to 2012.\n",
        "Florida has no top income tax rate decreases in 2000 to 2012.\n",
        "Alaska has no top income tax rate decreases in 2000 to 2012.\n",
        "Wisconsin has no top income tax rate decreases in 2000 to 2012.\n",
        "Alabama has no top income tax rate decreases in 2000 to 2012.\n",
        "South Dakota has no top income tax rate decreases in 2000 to 2012.\n",
        "Washington has no top income tax rate decreases in 2000 to 2012.\n",
        "Tennessee has no top income tax rate decreases in 2000 to 2012.\n",
        "Texas has no top income tax rate decreases in 2000 to 2012.\n",
        "Nevada has no top income tax rate decreases in 2000 to 2012.\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 61,
       "text": [
        "{'Arkansas': array([2005], dtype=int64),\n",
        " 'Hawaii': array([2002], dtype=int64),\n",
        " 'Idaho': array([2001], dtype=int64),\n",
        " 'Iowa': array([2008]),\n",
        " 'Kansas': array([2008]),\n",
        " 'Maryland': array([2002, 2006], dtype=int64),\n",
        " 'Massachusetts': array([2002], dtype=int64),\n",
        " 'Michigan': array([2005], dtype=int64),\n",
        " 'Nebraska': array([2008]),\n",
        " 'Rhode Island': array([2002], dtype=int64),\n",
        " 'Utah': array([2008]),\n",
        " 'Vermont': array([2001], dtype=int64),\n",
        " 'Washington DC': array([2001], dtype=int64)}"
       ]
      }
     ],
     "prompt_number": 61
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This leaves far fewer comparisons than we had originally. From 50 states + Washington D.C. in 13 years in the original we're now down to 14. It wouldn't be difficult to test whatever conclusions we reach using a three-year gap or five-year gap, but we'll start with four."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "con.close() #closes database relation"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 62
    }
   ],
   "metadata": {}
  }
 ]
}